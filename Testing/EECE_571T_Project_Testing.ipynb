{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EECE 571T Project - Testing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ifCzi282UO64",
        "UFTJfJkrO06u",
        "LWVt__H7R9zl",
        "PLR3Zasdel1c",
        "xjaWwtbek649",
        "1av-NH6N034E",
        "wLKapia-1GDk",
        "DHP0--sCkC-z"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# EECE 571T Project - NLP with Emotion Dataset\n",
        "\n",
        "Last updated:\n",
        "* Date: February 17, 2022\n",
        "* Time: 5:50pm"
      ],
      "metadata": {
        "id": "ELaILu9SPaoy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References:\n",
        "\n",
        "* Making our own word2vec model: https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/\n",
        "* https://medium.com/@adriensieg/text-similarities-da019229c894\n",
        "* Text Classification tutorial: https://github.com/adsieg/Multi_Text_Classification\n",
        "* From same author:\n",
        "  * [**Feb.17**] https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794 (Try following these instructions next)\n",
        "  * [**Feb.17**] https://towardsdatascience.com/text-analysis-feature-engineering-with-nlp-502d6ea9225d\n"
      ],
      "metadata": {
        "id": "ifCzi282UO64"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get data from GitHub repo"
      ],
      "metadata": {
        "id": "UFTJfJkrO06u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "724_Q82ZOihs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f769a5cb-a735-4665-e56e-fd20f7bb7c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-18 00:45:12--  https://github.com/tkjsung/EECE571T_Dataset/archive/refs/heads/master.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/tkjsung/EECE571T_Dataset/zip/refs/heads/master [following]\n",
            "--2022-02-18 00:45:12--  https://codeload.github.com/tkjsung/EECE571T_Dataset/zip/refs/heads/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.112.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.112.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip.1’\n",
            "\n",
            "master.zip.1            [  <=>               ] 798.87K  3.23MB/s    in 0.2s    \n",
            "\n",
            "2022-02-18 00:45:13 (3.23 MB/s) - ‘master.zip.1’ saved [818042]\n",
            "\n",
            "Archive:  /content/master.zip\n",
            "f84fef58c648047c03c671498e0375bf224f000e\n",
            "replace EECE571T_Dataset-master/.gitignore? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!wget https://github.com/tkjsung/EECE571T_Dataset/archive/refs/heads/master.zip\n",
        "!unzip /content/master.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Data"
      ],
      "metadata": {
        "id": "LWVt__H7R9zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries for data import\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "iKV__yZmPWsQ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV\n",
        "data_train = pd.read_csv('/content/EECE571T_Dataset-master/Project/train.txt',sep=';', header=None)\n",
        "data_test = pd.read_csv('/content/EECE571T_Dataset-master/Project/test.txt',sep=';', header=None)\n",
        "data_val = pd.read_csv('/content/EECE571T_Dataset-master/Project/val.txt',sep=';', header=None)\n",
        "\n",
        "col_names = [\"sentence\",\"emotion\"]\n",
        "data_train.columns = col_names\n",
        "data_test.columns = col_names\n",
        "data_val.columns = col_names"
      ],
      "metadata": {
        "id": "mMWomGTaPSES"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See the data head to make sure data is imported correctly.\n",
        "data_train.head()\n",
        "# data_test.head()\n",
        "# data_val.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "GC4V-55GSaVT",
        "outputId": "7f221258-1e7e-43f5-b9cb-09c2f9fe1b81"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-59a00f45-f548-4aba-8186-77059d355621\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59a00f45-f548-4aba-8186-77059d355621')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59a00f45-f548-4aba-8186-77059d355621 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59a00f45-f548-4aba-8186-77059d355621');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            sentence  emotion\n",
              "0                            i didnt feel humiliated  sadness\n",
              "1  i can go from feeling so hopeless to so damned...  sadness\n",
              "2   im grabbing a minute to post i feel greedy wrong    anger\n",
              "3  i am ever feeling nostalgic about the fireplac...     love\n",
              "4                               i am feeling grouchy    anger"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode the emotion labels with unique identifiers"
      ],
      "metadata": {
        "id": "PLR3Zasdel1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Encode the emotion labels with unique identifiers\n",
        "data_train['emotion'].unique()\n",
        "labelencoder = LabelEncoder()\n",
        "data_train['label_enc'] = labelencoder.fit_transform(data_train['emotion'])\n",
        "data_test['label_enc'] = labelencoder.fit_transform(data_test['emotion'])\n",
        "data_val['label_enc'] = labelencoder.fit_transform(data_val['emotion'])\n",
        "# For data_test and data_val, use the same labelencoder. Make sure it's the same by using the display code below."
      ],
      "metadata": {
        "id": "oFJvTfXTdrN6"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the encoded emotion labels"
      ],
      "metadata": {
        "id": "X-bBnrKVoiBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train[['emotion','label_enc']].drop_duplicates(keep='first')\n",
        "# data_test[['emotion','label_enc']].drop_duplicates(keep='first')\n",
        "# data_val[['emotion','label_enc']].drop_duplicates(keep='first')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "kkm7wEN1fnMX",
        "outputId": "ecac29ac-27f8-4ce0-8811-f7159f11f356"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d0610163-2d5a-4687-a37a-1c4c83f12b35\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>label_enc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sadness</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>anger</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>love</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>surprise</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>fear</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>joy</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0610163-2d5a-4687-a37a-1c4c83f12b35')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d0610163-2d5a-4687-a37a-1c4c83f12b35 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d0610163-2d5a-4687-a37a-1c4c83f12b35');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    emotion  label_enc\n",
              "0   sadness          4\n",
              "2     anger          0\n",
              "3      love          3\n",
              "6  surprise          5\n",
              "7      fear          1\n",
              "8       joy          2"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add sentence length to each sentence. It should calculate number of characters, including spaces and punctuation."
      ],
      "metadata": {
        "id": "zhyCE_IromWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train['length'] = [len(x) for x in data_train['sentence']]\n",
        "data_test['length'] = [len(x) for x in data_test['sentence']]\n",
        "data_val['length'] = [len(x) for x in data_val['sentence']]\n",
        "# data_train.head()\n",
        "# data_test.head()\n",
        "# data_val.head()"
      ],
      "metadata": {
        "id": "L0bFupawluI7"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.head()\n",
        "# data_test.head()\n",
        "# data_val.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "lLROznaxHPNU",
        "outputId": "be97a0ea-b1c6-42cd-f120-6411ffa67105"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cff612f9-15f3-4f28-b518-05f750e4ad83\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>emotion</th>\n",
              "      <th>label_enc</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>sadness</td>\n",
              "      <td>4</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>4</td>\n",
              "      <td>108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>anger</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>love</td>\n",
              "      <td>3</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>anger</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cff612f9-15f3-4f28-b518-05f750e4ad83')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cff612f9-15f3-4f28-b518-05f750e4ad83 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cff612f9-15f3-4f28-b518-05f750e4ad83');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            sentence  ... length\n",
              "0                            i didnt feel humiliated  ...     23\n",
              "1  i can go from feeling so hopeless to so damned...  ...    108\n",
              "2   im grabbing a minute to post i feel greedy wrong  ...     48\n",
              "3  i am ever feeling nostalgic about the fireplac...  ...     92\n",
              "4                               i am feeling grouchy  ...     20\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding the maximum sentence length. It seems to be 300. From the testing and validation set, they are 296 and 295, respectively."
      ],
      "metadata": {
        "id": "9IU3wyOOocsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = data_train['length'].max()\n",
        "print(max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhBSqPnQoL-l",
        "outputId": "bc71d8c4-7d7c-4704-be31-f298d475328e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning & Pre-Processing"
      ],
      "metadata": {
        "id": "0DW_8szfEo1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to do some data cleaning first, otherwise it would be a nightmare to do pre-processing with at least 15212 vocabulary words..."
      ],
      "metadata": {
        "id": "xKULabmoEqMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Tokenize the words. This uses `keras.preprocessing` library. We get a tokenizer that fits onto our training set's sentences. Then a dictionary of words is created from the tokenizer. -->\n",
        "\n",
        "*Feb.16: Instructions in this code block is commented out*"
      ],
      "metadata": {
        "id": "WP_zCSh79y5Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, data cleaning.<br>\n",
        "**Feb.17:** For stemming, I think we should replace it with lemmization, which looks to be better and would probably work better for word2vec.\n",
        "Source: https://blog.bitext.com/what-is-the-difference-between-stemming-and-lemmatization/"
      ],
      "metadata": {
        "id": "hHVXM1f4iYf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Attempting data cleaning here\n",
        "def preprocess(raw_text):\n",
        "    # keep only words\n",
        "    letters_only_text = re.sub(\"[^a-zA-Z]\", \" \", raw_text)\n",
        "\n",
        "    # convert to lower case and split \n",
        "    words = letters_only_text.lower().split()\n",
        "\n",
        "    # remove stopwords\n",
        "    stopword_set = set(stopwords.words(\"english\"))\n",
        "    meaningful_words = [w for w in words if w not in stopword_set]\n",
        "    \n",
        "    #stemmed words (looks like this is causing some words to be weird)\n",
        "    ps = PorterStemmer()\n",
        "    stemmed_words = [ps.stem(word) for word in meaningful_words]\n",
        "\n",
        "    #lemmed words (trying this because this gets the root word?)\n",
        "    lem = WordNetLemmatizer()\n",
        "    lemmed_words = [lem.lemmatize(word) for word in meaningful_words]\n",
        "    \n",
        "    #join the cleaned words in a list\n",
        "    # cleaned_word_list = \" \".join(stemmed_words)\n",
        "    cleaned_word_list = \" \".join(lemmed_words)\n",
        "    # cleaned_word_list = \" \".join(meaningful_words)\n",
        "\n",
        "    return cleaned_word_list"
      ],
      "metadata": {
        "id": "pJWWXLcFdzc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train['sentence'] = data_train['sentence'].apply(lambda line : preprocess(line))\n",
        "data_test['sentence'] = data_test['sentence'].apply(lambda line : preprocess(line))\n",
        "data_val['sentence'] = data_val['sentence'].apply(lambda line : preprocess(line))"
      ],
      "metadata": {
        "id": "schsncvleDrh"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize text and vectorize. (This is literally TF-IDF, as per Tensorflow's documentation)"
      ],
      "metadata": {
        "id": "mlYMLkDjiqVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import text\n",
        "token = text.Tokenizer() # uses keras.preprocessing I believe"
      ],
      "metadata": {
        "id": "buLUD-rfdvS2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token.fit_on_texts(data_train['sentence'])\n",
        "word_index = token.word_index"
      ],
      "metadata": {
        "id": "dxwFfYZW1KmA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text to sequence\n",
        "x_train_token = token.texts_to_sequences(data_train['sentence'])\n",
        "x_test_token = token.texts_to_sequences(data_test['sentence'])\n",
        "x_val_token = token.texts_to_sequences(data_val['sentence'])"
      ],
      "metadata": {
        "id": "AaakCiM3c0pw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pad the data sets to be of the same length"
      ],
      "metadata": {
        "id": "TwG1MSVLi5Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def checkLength(listArr):\n",
        "  max = 0\n",
        "  for i in range(0,len(listArr)):\n",
        "    if(max < len(listArr[i])):\n",
        "      max = len(listArr[i])\n",
        "  return max\n",
        "print(checkLength(x_train_token))\n",
        "print(checkLength(x_test_token))\n",
        "print(checkLength(x_val_token))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDNYmSwRi49k",
        "outputId": "3149ef9d-dcf9-4191-8430-27b5317d2604"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35\n",
            "30\n",
            "29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Max length is 35. Pad all arrays to be of size 35."
      ],
      "metadata": {
        "id": "Aylls2V6kAhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to add padding code here"
      ],
      "metadata": {
        "id": "OEs7s4vSkENi"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using word2vec\n",
        "\n",
        "I did pre-processing, word stemming, and stuff like that above. The simplest way avoid words not being found in a database is if word stemming is not performed on the dataset (or as I just found out, use lemmization instead. More computationally complex but better for actually working with word embedding techniques (I think))."
      ],
      "metadata": {
        "id": "WDtYhj0SaH7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "~~**February 16:**~~ Find words in the Word2VecKeyedVector (using 2.3 in source https://github.com/adsieg/Multi_Text_Classification/blob/master/%5BIntroduction%5D%20-%20Big%20tutorial%20-%20Text%20Classification.ipynb) by using `Word2VecKeyedVector.index2word`. This returns a list of the word2vec array."
      ],
      "metadata": {
        "id": "IyQ0gXpbrWuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT RUN THIS BLOCK MORE THAN ONCE IN ONE SESSION\n",
        "# Import gensim data\n",
        "import gensim.downloader as api\n",
        "import gensim\n",
        "# Load word2vec model\n",
        "# Gensim data obtained from https://github.com/RaRe-Technologies/gensim-data (official source)\n",
        "model = api.load('glove-twitter-25')\n",
        "# model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
        "\n",
        "# Check dimension of word vectors\n",
        "# model.vector_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4X05qMsQmcl",
        "outputId": "4e6547c4-97e8-488a-c62e-5b3846f74cd8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing: Gets the index of where the embedded model\n",
        "# model.vocab[\"whatever\"].index\n",
        "# Now use the source above, section 2.3 and follow instructions there.\n",
        "# (And write it in the section below)"
      ],
      "metadata": {
        "id": "hZRSSdaxsMy3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embeddings_index = {}\n",
        "# for line in model:\n",
        "#   # values = line.split()\n",
        "#   embeddings_index[values[0]] = numpy.asarray(values[1:], dtype='float32')"
      ],
      "metadata": {
        "id": "b9Kc_344YIiH"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IGNORE THINGS IN THIS SECTION."
      ],
      "metadata": {
        "id": "xjaWwtbek649"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ignore code blocks below this one please.**"
      ],
      "metadata": {
        "id": "OcywnEKFVxd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Filter out stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# words = [word for word in words if not word in stop_words]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WdV1IG0JCWf",
        "outputId": "db7f03f3-7b2b-4325-bff1-716924a40fbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras_preprocessing.text import Tokenizer\n",
        "# tokenizer = Tokenizer()\n",
        "# tokenizer.fit_on_texts(pd.concat(data_train, axis=0))"
      ],
      "metadata": {
        "id": "NC31INsoHmNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabSize = 15000"
      ],
      "metadata": {
        "id": "eZjIwxrqH487"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding will require the text to be already in numbers... so I can't run this yet."
      ],
      "metadata": {
        "id": "4OGxJ0j5O__d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from nltk.stem.porter import PorterStemmer\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# import re\n",
        "\n",
        "# def text_cleaning(df, column):\n",
        "#   stemmer = PorterStemmer()\n",
        "#   corpus = []\n",
        "\n",
        "#   for text in df[column]:\n",
        "#     text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
        "#     text = text.lower()\n",
        "#     text = text.split()\n",
        "#     text = [stemmer.stem(word) for word in text if word not in stop_words]\n",
        "#     text = \" \".join(text)\n",
        "#     corpus.append(text)\n",
        "  \n",
        "#   # pad = pad_sequences(sequences=corpus, maxlen=max_len, padding='pre')\n",
        "#   # return pad\n",
        "#   return corpus"
      ],
      "metadata": {
        "id": "rl0_r2neH690"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_train_clean = text_cleaning(data_train, 'sentence')\n",
        "# data_test_clean = text_cleaning(data_test, 'sentence')\n",
        "# data_val_clean = text_cleaning(data_val, 'sentence')"
      ],
      "metadata": {
        "id": "nVLWdKpaKfex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-Processing: Method 1\n",
        "\n",
        "Source: https://towardsdatascience.com/using-word2vec-to-analyze-news-headlines-and-predict-article-success-cdeda5f14751"
      ],
      "metadata": {
        "id": "1av-NH6N034E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "\n",
        "import pandas, xgboost, numpy, textblob, string\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers\n",
        "\n",
        "# train_seq_x = sequence.pad_sequences(token.texts_to_sequences(data_train['sentence']), maxlen=300)\n",
        "# test_seq_x = sequence.pad_sequences(token.texts_to_sequences(data_test['sentence']), maxlen=300)\n",
        "# valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(data_val['sentence']), maxlen=300)"
      ],
      "metadata": {
        "id": "S0TCQh74V32I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create list of strings into a single long string for processing\n",
        "# title_list = [title for title in data_train['sentence']]\n",
        "\n",
        "# We definitely are not doing this.\n",
        "# Collapse the list of strings into a single long string for processing\n",
        "# big_title_string = ' '.join(title_list)"
      ],
      "metadata": {
        "id": "1yLxfHPCx4fD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import nltk\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "Lxp_sIod0NjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from nltk.tokenize import word_tokenize\n",
        "# Tokenize the string into words\n",
        "# tokens = word_tokenize(big_title_string)\n",
        "\n",
        "# Filter out stopwords\n",
        "# from nltk.corpus import stopwords\n",
        "# stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# words = [word for word in words if not word in stop_words]"
      ],
      "metadata": {
        "id": "O2mvRI_nzT4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-Processing: Method 2\n",
        "\n",
        "Sources:\n",
        "\n",
        "* https://github.com/adsieg/Multi_Text_Classification/blob/master/%5BIntroduction%5D%20-%20Big%20tutorial%20-%20Text%20Classification.ipynb\n",
        "* https://www.tensorflow.org/text/guide/word_embeddings\n",
        "* Only BOW and TF-IDF: https://www.analyticsvidhya.com/blog/2021/06/part-5-step-by-step-guide-to-master-nlp-text-vectorization-approaches/"
      ],
      "metadata": {
        "id": "wLKapia-1GDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "\n",
        "import pandas, xgboost, numpy, textblob, string\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers"
      ],
      "metadata": {
        "id": "4D4g0Y622mgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_train['length'] = [len(x) for x in token]\n",
        "# data_train.head()\n",
        "# max_len = data_train['length'].max()\n",
        "# print(max_len)"
      ],
      "metadata": {
        "id": "RQtB1K1x3UU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Vectorization\n",
        "\n",
        "We can use the `gensim` library to train our own word2vec model on a custom corpus either with CBOW or Skip Gram."
      ],
      "metadata": {
        "id": "DHP0--sCkC-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "word2vec cannot create a vector from a word that is not in its vocabulary. So we need to specify \"if word in model.vocab\" when creating the full list of word vectors (source: https://towardsdatascience.com/using-word2vec-to-analyze-news-headlines-and-predict-article-success-cdeda5f14751)"
      ],
      "metadata": {
        "id": "9b9z05AQyy4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Relevant Libraries for Word Vectorization\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# !pip install nltk\n",
        "# !pip install gensim\n",
        "import gensim\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "nfwxCBpUmCBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CBOW model\n",
        "# model1 = gensim.models.Word2Vec(data_train, min_count=1, size=100, window=5)\n",
        "# Skip Gram Model\n",
        "# model2 = gensim.models.Word2Vec(data_train, min_count=1, size=100, window=5,sg=1)\n",
        "# model1.build_vocab()"
      ],
      "metadata": {
        "id": "Rcz8xO0fUK02"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}