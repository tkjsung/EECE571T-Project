{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELaILu9SPaoy"
   },
   "source": [
    "# EECE 571T Project - NLP with Emotion Dataset (BERT)\n",
    "\n",
    "Focus: BERT\n",
    "<br>\n",
    "Author: Tom Sung\n",
    "\n",
    "Last updated:\n",
    "* Date: March 9, 2022\n",
    "* Time: 9:52pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifCzi282UO64",
    "tags": []
   },
   "source": [
    "## References\n",
    "\n",
    "* Text Classification tutorial: https://github.com/adsieg/Multi_Text_Classification\n",
    "* From same author:\n",
    "    * [**Feb.17**] This is used for the Word Embedding part: https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794 (Try following these instructions next)\n",
    "    * [**Feb.17**] https://towardsdatascience.com/text-analysis-feature-engineering-with-nlp-502d6ea9225d\n",
    "* Different Pre-Processing Techniques with Bag of Words w/ TF-IDF, Word Embedding, and BERT: https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following to use macOS's GPU\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "print(os.environ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFTJfJkrO06u",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Get data from GitHub repo\n",
    "\n",
    "**Only run this once even after if notebook environment is cleared via** `%reset -f`. The code written here imports the Kaggle data set, which I have placed on my public GitHub repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "724_Q82ZOihs",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-10 17:21:16--  https://github.com/tkjsung/EECE571T_Dataset/archive/refs/heads/master.zip\n",
      "Resolving github.com (github.com)... 140.82.112.4\n",
      "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://codeload.github.com/tkjsung/EECE571T_Dataset/zip/refs/heads/master [following]\n",
      "--2022-03-10 17:21:17--  https://codeload.github.com/tkjsung/EECE571T_Dataset/zip/refs/heads/master\n",
      "Resolving codeload.github.com (codeload.github.com)... 140.82.114.9\n",
      "Connecting to codeload.github.com (codeload.github.com)|140.82.114.9|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: ‘master.zip’\n",
      "\n",
      "master.zip              [    <=>             ] 798.87K   953KB/s    in 0.8s    \n",
      "\n",
      "2022-03-10 17:21:18 (953 KB/s) - ‘master.zip’ saved [818042]\n",
      "\n",
      "unzip:  cannot find or open /content/master.zip, /content/master.zip.zip or /content/master.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/tkjsung/EECE571T_Dataset/archive/refs/heads/master.zip\n",
    "!unzip /content/master.zip\n",
    "# For local computer use:\n",
    "# !unzip master.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWVt__H7R9zl",
    "tags": []
   },
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iKV__yZmPWsQ"
   },
   "outputs": [],
   "source": [
    "# Import libraries for data import\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mMWomGTaPSES"
   },
   "outputs": [],
   "source": [
    "# Read CSV\n",
    "# data_train = pd.read_csv('/content/EECE571T_Dataset-master/Project/train.txt',sep=';', header=None)\n",
    "# data_test = pd.read_csv('/content/EECE571T_Dataset-master/Project/test.txt',sep=';', header=None)\n",
    "# data_val = pd.read_csv('/content/EECE571T_Dataset-master/Project/val.txt',sep=';', header=None)\n",
    "\n",
    "# Read CSV on local computer\n",
    "data_train = pd.read_csv('EECE571T_Dataset-master/Project/train.txt',sep=';', header=None)\n",
    "data_test = pd.read_csv('EECE571T_Dataset-master/Project/test.txt',sep=';', header=None)\n",
    "data_val = pd.read_csv('EECE571T_Dataset-master/Project/val.txt',sep=';', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AtXW9_Z2Pbtq"
   },
   "outputs": [],
   "source": [
    "col_names = [\"sentence\",\"emotion\"]\n",
    "data_train.columns = col_names\n",
    "data_test.columns = col_names\n",
    "data_val.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "id": "GC4V-55GSaVT",
    "outputId": "d40f8716-5033-4b46-c725-f95203e4dc1d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  emotion\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the data head to make sure data is imported correctly.\n",
    "data_train.head()\n",
    "# data_test.head()\n",
    "# data_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLR3Zasdel1c",
    "tags": []
   },
   "source": [
    "## Encode the emotion labels with unique identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oFJvTfXTdrN6"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Encode the emotion labels with unique identifiers\n",
    "data_train['emotion'].unique()\n",
    "labelencoder = LabelEncoder()\n",
    "data_train['emotion_enc'] = labelencoder.fit_transform(data_train['emotion'])\n",
    "data_test['emotion_enc'] = labelencoder.fit_transform(data_test['emotion'])\n",
    "data_val['emotion_enc'] = labelencoder.fit_transform(data_val['emotion'])\n",
    "# For data_test and data_val, use the same labelencoder. Make sure it's the same by using the display code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-bBnrKVoiBT"
   },
   "source": [
    "Display the encoded emotion labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "kkm7wEN1fnMX",
    "outputId": "786c915a-ecc8-4bd2-910e-32e4b9d8dc4b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>surprise</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>joy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    emotion  emotion_enc\n",
       "0   sadness            4\n",
       "2     anger            0\n",
       "3      love            3\n",
       "6  surprise            5\n",
       "7      fear            1\n",
       "8       joy            2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[['emotion','emotion_enc']].drop_duplicates(keep='first')\n",
    "# data_test[['emotion','emotion_enc']].drop_duplicates(keep='first')\n",
    "# data_val[['emotion','emotion_enc']].drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhyCE_IromWn"
   },
   "source": [
    "[OLD-Don't need this] ~Add sentence length to each sentence. It should calculate number of characters, including spaces and punctuation.~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "L0bFupawluI7"
   },
   "outputs": [],
   "source": [
    "# data_train['length'] = [len(x) for x in data_train['sentence']]\n",
    "# data_test['length'] = [len(x) for x in data_test['sentence']]\n",
    "# data_val['length'] = [len(x) for x in data_val['sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "id": "lLROznaxHPNU",
    "outputId": "e6c00efa-0076-460d-f1a5-bcf06062832a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling quite sad and sorry for myself but ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel like i am still looking at a blank canv...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i feel like a faithful servant</td>\n",
       "      <td>love</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am just feeling cranky and blue</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i can have for a treat or if i am feeling festive</td>\n",
       "      <td>joy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  emotion  emotion_enc\n",
       "0  im feeling quite sad and sorry for myself but ...  sadness            4\n",
       "1  i feel like i am still looking at a blank canv...  sadness            4\n",
       "2                     i feel like a faithful servant     love            3\n",
       "3                  i am just feeling cranky and blue    anger            0\n",
       "4  i can have for a treat or if i am feeling festive      joy            2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()\n",
    "data_test.head()\n",
    "data_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IU3wyOOocsQ"
   },
   "source": [
    "[OLD-Unncessary] ~Finding the maximum sentence length. It seems to be 300. From the testing and validation set, they are 296 and 295, respectively.~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hhBSqPnQoL-l"
   },
   "outputs": [],
   "source": [
    "# max_len = data_train['length'].max()\n",
    "# print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DW_8szfEo1T",
    "tags": []
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKULabmoEqMt"
   },
   "source": [
    "We need to do some data cleaning first~, otherwise it would be a nightmare to do pre-processing with at least 15212 vocabulary words...~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uE7b3QZrB6O"
   },
   "source": [
    "**Data Cleaning Process:** Keep only words, convert all words to lowercase, split all words, remove stopwords, lemmization for word root.<br>\n",
    "The result of all of this work is a cleaned data vocab list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHVXM1f4iYf6"
   },
   "source": [
    "Replace stemming with lemmization, which keeps the actual form of the word better. This is necessary for using pre-existing word embedding models.\n",
    "Source: https://blog.bitext.com/what-is-the-difference-between-stemming-and-lemmatization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJWWXLcFdzc1",
    "outputId": "1bfd25ae-767b-482a-8a81-935a421367f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/tomsung/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tomsung/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/tomsung/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/tomsung/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Attempting data cleaning here\n",
    "def preprocess(raw_text):\n",
    "    # keep only words\n",
    "    letters_only_text = re.sub(\"[^a-zA-Z]\", \" \", raw_text)\n",
    "\n",
    "    # convert to lower case and split \n",
    "    words = letters_only_text.lower().split()\n",
    "\n",
    "    # remove stopwords\n",
    "    stopword_set = set(stopwords.words(\"english\"))\n",
    "    meaningful_words = [w for w in words if w not in stopword_set]\n",
    "    \n",
    "    # stemmed words (looks like this is causing some words to be weird)\n",
    "    # ps = PorterStemmer()\n",
    "    # stemmed_words = [ps.stem(word) for word in meaningful_words]\n",
    "\n",
    "    # lemmed words (trying this because this gets the root word?)\n",
    "    lem = WordNetLemmatizer()\n",
    "    lemmed_words = [lem.lemmatize(word) for word in meaningful_words]\n",
    "    \n",
    "    # join the cleaned words in a list\n",
    "    # cleaned_word_list = \" \".join(stemmed_words)\n",
    "    cleaned_word_list = \" \".join(lemmed_words)\n",
    "    # cleaned_word_list = \" \".join(meaningful_words)\n",
    "\n",
    "    return cleaned_word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BmRPEeBpYZN"
   },
   "source": [
    "Apply data cleaning to all data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "schsncvleDrh"
   },
   "outputs": [],
   "source": [
    "data_train['sentence_cleaned'] = data_train['sentence'].apply(lambda line : preprocess(line))\n",
    "data_test['sentence_cleaned'] = data_test['sentence'].apply(lambda line : preprocess(line))\n",
    "data_val['sentence_cleaned'] = data_val['sentence'].apply(lambda line : preprocess(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rb9vzfUAqXoZ",
    "tags": []
   },
   "source": [
    "## Pre-Processing and Training\n",
    "\n",
    "Pre-processing and training is bundled together as the different methods use different pre-processing steps.<br>\n",
    "There are several methods available: Bag-of-words with TF-IDF, Word Embedding using ~Word2Vec~ [I used GloVe, not Word2Vec] (unknown NN), and BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cEZB9u7ZOvR"
   },
   "source": [
    "### METHOD 2: BERT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMPQ0676j_BB",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Histogram: Uncleaned Sentences\n",
    "\n",
    "Let's find out how long the uncleaned sentence is, since the example link does not do data cleaning on the sentences in the sense that common stop words are still provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ylfhpf-EjyGA"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import seaborn as sns\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data_train[\"sentence\"])\n",
    "dic_vocabulary = tokenizer.word_index\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(data_train[\"sentence\"])\n",
    "X_test = tokenizer.texts_to_sequences(data_test[\"sentence\"])\n",
    "X_val = tokenizer.texts_to_sequences(data_val[\"sentence\"])\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QT27TvOxgWWi",
    "outputId": "b9fd15a0-19a8-4bb8-c1c0-1ab91174508f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train, Longest ID: 66, Average ID length: 19.1663125\n",
      "X_test, Longest ID: 60, Average ID length: 18.634\n",
      "X_val, Longest ID: 61, Average ID length: 18.3535\n"
     ]
    }
   ],
   "source": [
    "# string_name = ['X_train', 'X_test', 'X_val']\n",
    "dict_data = {'X_train': X_train,\n",
    "             'X_test': X_test,\n",
    "             'X_val': X_val}\n",
    "histo_plot_data = np.zeros((3,66))\n",
    "\n",
    "tmp_counter = 0;\n",
    "for key, value in dict_data.items():\n",
    "    feedback = 0;\n",
    "    feedback_sum = 0;\n",
    "    for i in value:\n",
    "        histo_plot_data[tmp_counter, len(i)-1] += 1\n",
    "        feedback_sum += len(i)\n",
    "        if len(i) > feedback:\n",
    "            feedback = len(i)\n",
    "    print(f\"{key}, Longest ID: {feedback}, Average ID length: {feedback_sum/len(value)}\")\n",
    "    tmp_counter += 1\n",
    "del tmp_counter\n",
    "\n",
    "# Longest sentence has 35 elements. Average is around 10.\n",
    "# TODO: This value, which influences padding, should be adjusted I think...\n",
    "# maxlen = 20\n",
    "\n",
    "# Delete unneeded variables\n",
    "del X_train, X_test, X_val, vocab_size, dic_vocabulary, tokenizer, feedback\n",
    "del feedback_sum, dict_data, tmp_counter, i, key, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "F6fuYFdZkTdJ",
    "outputId": "85ea4de4-d3e4-40bf-eae0-f75cf59035d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 66 artists>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the ID histogram to see the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.barh(range(1,66+1), histo_plot_data[0,:])\n",
    "plt.barh(range(1,66+1), histo_plot_data[1,:])\n",
    "plt.barh(range(1,66+1), histo_plot_data[2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rj_ZNEvTknNt"
   },
   "source": [
    "#### BERT Model (Using HuggingFace transformers library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LNgE8FNJZUm9",
    "outputId": "cecdf713-3819-4b32-ffcd-55197017571b"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ki2YxvB6aLFm",
    "outputId": "ff6412b7-283b-401f-f81e-e317d6c5b93f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_projector', 'vocab_layer_norm', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# BERT tokenizer\n",
    "# tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('distilbert-base-uncased', num_labels=6, do_lower_case=True)\n",
    "# tokenizer = transformers.AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=6, do_lower_case=True)\n",
    "# test_nlp_recognizer = pipeline(\"sentiment-analysis\", model=\"prajjwal1/bert-tiny\")\n",
    "\n",
    "# BERT Model\n",
    "config = transformers.DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n",
    "# config = transformers.AutoConfig(dropout=0.2, attention_dropout=0.2)\n",
    "# config = transformers.AutoConfig.from_pretrained(\"prajjwal1/bert-tiny\", hidden_dropout_prob=0.2)\n",
    "config.output_hidden_states = False\n",
    "\n",
    "nlp = transformers.TFDistilBertModel.from_pretrained('distilbert-base-uncased', config=config)\n",
    "# nlp = transformers.AutoModel.from_pretrained(\"prajjwal1/bert-tiny\", config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gV9CPtK3lgLh"
   },
   "source": [
    "From the website (https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794): <br>\n",
    "*First of all, we need to select the sequence max length. This time I’m gonna choose a much larger number (i.e. 50) because BERT splits unknown words into sub-tokens until it finds a known unigrams. For example, if a made-up word like “zzdata” is given, BERT would split it into [“z”, “##z”, “##data”]. Moreover, we have to insert special tokens into the input text, then generate masks and segments. Finally, put all together in a tensor to get the feature matrix that will have the shape of 3 (ids, masks, segments) x Number of documents in the corpus x Sequence length*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIuzBeJQmpT9"
   },
   "source": [
    "So a summary of the large paragraph above:\n",
    "In BERT, we have three things to keep track of\n",
    "1. Token ID: The \"regular\" tokenization. \n",
    "    *  This includes text start token (101), unknown word (100) token, text end token (102), and padding token (0)\n",
    "2. Mask: Distinguishes between text and padding. 0 indicates padding\n",
    "3. Segment: Keeps track of the text end ([SEP]) token\n",
    "\n",
    "Now, we are not using code from the link above. I have directly used the tokenizer object itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "3tWIPHkdAxZi",
    "outputId": "7e48ed3a-b8be-457e-bda3-cb98c06c00a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: Longest sentence using BERT Tokenization is 72 at index 9753.\n",
      "Average ID length: 12.403\n",
      "X_val: Longest sentence using BERT Tokenization is 57 at index 197.\n",
      "Average ID length: 12.1905\n",
      "X_test: Longest sentence using BERT Tokenization is 44 at index 591.\n",
      "Average ID length: 12.3155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 87 artists>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    del idx, masks, segments\n",
    "except:\n",
    "    pass\n",
    "\n",
    "histo_plot_data = np.zeros((3,87))\n",
    "# Set max length of the sentence\n",
    "maxlen=20\n",
    "\n",
    "# I really should be using data cleaning that I used for Word Embedding, but let's have something working first.\n",
    "def bert_tokenize(corpus, dataset_str):\n",
    "    histo_plot_data = np.zeros((87))\n",
    "    # corpus = data_train[\"sentence_cleaned\"]\n",
    "    idx, masks, segments = [], [], []\n",
    "    longest = 0\n",
    "    longest_index = 0;\n",
    "    feedback_sum = 0\n",
    "\n",
    "    for i, element in enumerate(corpus):\n",
    "\n",
    "        tmp = tokenizer(element)\n",
    "        idx.append(tmp[\"input_ids\"])\n",
    "        masks.append(tmp[\"attention_mask\"])\n",
    "        # segments.append(tmp[\"token_type_ids\"])\n",
    "        \n",
    "        if len(tmp[\"input_ids\"]) > longest:\n",
    "            longest = len(tmp[\"input_ids\"])\n",
    "            longest_index = i\n",
    "\n",
    "        histo_plot_data[len(tmp[\"input_ids\"])-1] += 1\n",
    "        feedback_sum += len(tmp[\"input_ids\"])\n",
    "\n",
    "        # corpus_tokenized.append(tmp)\n",
    "    print(f\"{dataset_str}: Longest sentence using BERT Tokenization is {longest} at index {longest_index}.\")\n",
    "    print(f\"Average ID length: {feedback_sum/len(corpus)}\")\n",
    "\n",
    "    for i, element in enumerate(idx):\n",
    "        tmp = maxlen - len(element)\n",
    "        if tmp > 0:\n",
    "            idx[i] += tmp*[0]\n",
    "            masks[i] += tmp*[0]\n",
    "            # segments[i] += tmp*[1]\n",
    "        else:\n",
    "            idx[i] = idx[i][0:maxlen]\n",
    "            idx[i][maxlen-1] = 102\n",
    "            masks[i] = masks[i][0:maxlen]\n",
    "            # segments[i] = segments[i][0:maxlen]\n",
    "    return [np.asarray(idx, dtype='int32'), np.asarray(masks, dtype='int32')], histo_plot_data\n",
    "\n",
    "X_train, histo_plot_data[0,:]  = bert_tokenize(data_train[\"sentence_cleaned\"], 'X_train')\n",
    "X_val, histo_plot_data[1,:] = bert_tokenize(data_val[\"sentence_cleaned\"], 'X_val')\n",
    "X_test, histo_plot_data[2,:] = bert_tokenize(data_test[\"sentence_cleaned\"], 'X_test')\n",
    "\n",
    "# X_train=[np.asarray(idx, dtype='int32'), \n",
    "#          np.asarray(masks, dtype='int32')]\n",
    "\n",
    "# Plotting the ID histogram to see the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.barh(range(1,87+1), histo_plot_data[0,:])\n",
    "plt.barh(range(1,87+1), histo_plot_data[1,:])\n",
    "plt.barh(range(1,87+1), histo_plot_data[2,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07uPrJiyNOb4"
   },
   "outputs": [],
   "source": [
    "# X_train=[np.asarray(idx, dtype='int32'), \n",
    "#          np.asarray(masks, dtype='int32')]#, \n",
    "#         #  np.asarray(segments, dtype='int32')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIjDY0WsNHmv"
   },
   "source": [
    "BERT NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwwmQlfFNG4g",
    "outputId": "f30ac25b-337d-4429-d954-21b7fa3971bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_idx (InputLayer)         [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_masks (InputLayer)       [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " tf_distil_bert_model (TFDistil  TFBaseModelOutput(l  66362880   ['input_idx[0][0]',              \n",
      " BertModel)                     ast_hidden_state=(N               'input_masks[0][0]']            \n",
      "                                one, 20, 768),                                                    \n",
      "                                 hidden_states=None                                               \n",
      "                                , attentions=None)                                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 768)         0           ['tf_distil_bert_model[0][0]']   \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           49216       ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 6)            390         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66,412,486\n",
      "Trainable params: 66,412,486\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers, models, optimizers\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Inputs\n",
    "idx = layers.Input((maxlen), dtype='int32',name='input_idx')\n",
    "masks = layers.Input((maxlen), dtype='int32',name='input_masks')\n",
    "# segments = layers.Input((maxlen), dtype='int32',name='input_segments')\n",
    "\n",
    "# Pre-trained BERT\n",
    "# we already import nlp above, we are using that.\n",
    "\n",
    "# nlp = transformers.TFBertModel.from_pretrained('bert-base-uncased')\n",
    "bert_out = nlp([idx, masks])\n",
    "\n",
    "# fine-tuning\n",
    "x = layers.GlobalAveragePooling1D()(bert_out[0])\n",
    "# x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "# x = layers.Dense(64, activation='sigmoid')(x)\n",
    "y_out = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "model = models.Model([idx, masks], y_out)\n",
    "\n",
    "# The BERT model is pre-trained; we don't need to train that layer. Only train the last two Dense layers basically\n",
    "for layer in model.layers[:4]:\n",
    "    layer.trainable=False\n",
    "\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \n",
    "            #   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "            #   metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "            #   optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "8xn3kRMqSBop",
    "outputId": "490787c0-9d3d-42a3-b504-624f235f14e6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "320/320 [==============================] - 62s 175ms/step - loss: 1.6119 - accuracy: 0.3213 - val_loss: 1.5812 - val_accuracy: 0.3520\n",
      "Epoch 2/10\n",
      "320/320 [==============================] - 55s 173ms/step - loss: 1.5841 - accuracy: 0.3254 - val_loss: 1.6170 - val_accuracy: 0.2750\n",
      "Epoch 3/10\n",
      "320/320 [==============================] - 55s 172ms/step - loss: 1.5810 - accuracy: 0.3313 - val_loss: 1.5886 - val_accuracy: 0.2750\n",
      "Epoch 4/10\n",
      "320/320 [==============================] - 56s 174ms/step - loss: 1.5802 - accuracy: 0.3293 - val_loss: 1.6056 - val_accuracy: 0.2750\n",
      "Epoch 5/10\n",
      " 67/320 [=====>........................] - ETA: 42s - loss: 1.5953 - accuracy: 0.3134"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memotion_enc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_val\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memotion_enc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/eece571T/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/eece571T/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.pyenv/versions/eece571T/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/eece571T/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/eece571T/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.pyenv/versions/eece571T/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/eece571T/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/eece571T/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.pyenv/versions/eece571T/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=X_train, y=data_train['emotion_enc'], batch_size=50, epochs=10,\n",
    "                     shuffle=True, verbose=1, validation_data=[X_val, data_val['emotion_enc']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzhHn8vezOfu"
   },
   "outputs": [],
   "source": [
    "# Testing the tokenizer model...\n",
    "\n",
    "# text_test = [\"this is an amazing movie\", \"this is a crappy move on your part\"]\n",
    "# # text_preprocessed = bert_preprocess_model(text_test)\n",
    "# text_preprocessed = tokenizer(text_test)\n",
    "# print(text_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjW1a7SQwK57"
   },
   "source": [
    "#### Doing some other testing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rjxt-OnIlIh8"
   },
   "outputs": [],
   "source": [
    "# Get feature matrix\n",
    "# import re\n",
    "\n",
    "# corpus = data_train[\"sentence\"]\n",
    "\n",
    "# # Choose large maximum length as BERT splits made-up word into subtokens until it recognizes a word\n",
    "# # In our case, the longest sentence is 300 characters, so I'm just going to set maxlen to 300 for now\n",
    "# maxlen = 50\n",
    "\n",
    "# # add special tokens\n",
    "# maxqnans = int((maxlen-20)/2)\n",
    "# corpus_tokenized = [\"[CLS] \"+\n",
    "#              \" \".join(tokenizer.tokenize(re.sub(r'[^\\w\\s]+|\\n', '', \n",
    "#              str(txt).lower().strip()))[:maxqnans])+\n",
    "#              \" [SEP] \" for txt in corpus]\n",
    "\n",
    "# # generate masks\n",
    "# masks = [[1]*len(txt.split(\" \")) + [0]*(maxlen - len(txt.split(\" \"))) for txt in corpus_tokenized]\n",
    "\n",
    "# # Padding\n",
    "# txt2seq = [txt + \" [PAD]\"*(maxlen-len(txt.split(\" \"))) if len(txt.split(\" \")) != maxlen else txt for txt in corpus_tokenized]\n",
    "\n",
    "# # Generate idx\n",
    "# idx = [tokenizer.encode(seq.split(\" \")) for seq in txt2seq]\n",
    "\n",
    "# ## generate segments\n",
    "# segments = [] \n",
    "# for seq in txt2seq:\n",
    "#     temp, i = [], 0\n",
    "#     for token in seq.split(\" \"):\n",
    "#         temp.append(i)\n",
    "#         if token == \"[SEP]\":\n",
    "#              i += 1\n",
    "#     segments.append(temp)\n",
    "\n",
    "# ## feature matrix\n",
    "# X_train = [np.asarray(idx, dtype='int32'), \n",
    "#            np.asarray(masks, dtype='int32'), \n",
    "#            np.asarray(segments, dtype='int32')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DHy-Bp8urB69"
   },
   "outputs": [],
   "source": [
    "# i = 3\n",
    "# print(\"txt: \", data_train[\"sentence\"].iloc[0])\n",
    "# print(\"tokenized:\", [tokenizer.convert_ids_to_tokens(idx) for idx in X_train[0][i].tolist()])\n",
    "# print(\"idx: \", X_train[0][i])\n",
    "# print(\"mask: \", X_train[1][i])\n",
    "# print(\"segment: \", X_train[2][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RiEieHRndTzF"
   },
   "outputs": [],
   "source": [
    "# # Testing embedding with the BERT model\n",
    "# # Hidden layer with embeddings\n",
    "# txt = \"bank river\"\n",
    "# input_ids = np.array(tokenizer.encode(txt))[None, :]\n",
    "# embedding = nlp(input_ids)\n",
    "# embedding[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qM3f-vhqwJxd"
   },
   "outputs": [],
   "source": [
    "# !pip install \"tensorflow-text==2.8.*\"\n",
    "# !pip install tf-models-official==2.7.0\n",
    "# !pip install official.nlp\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import tensorflow_hub as hub\n",
    "# import tensorflow_text as text\n",
    "# from official.nlp import optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "lUUCZ6tWxyZ6"
   },
   "outputs": [],
   "source": [
    "#@title ~Commented Out: Choose a BERT model to fine-tune~\n",
    "\n",
    "# bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n",
    "\n",
    "# map_name_to_handle = {\n",
    "#     'bert_en_uncased_L-12_H-768_A-12':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "#     'bert_en_cased_L-12_H-768_A-12':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "#     'bert_multi_cased_L-12_H-768_A-12':\n",
    "#         'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "#     'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "#     'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "#     'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "#     'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "#     'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "#     'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "#     'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "#     'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "#     'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "#     'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "#     'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "#     'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "#     'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "#     'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "#     'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "#     'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "#     'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "#     'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "#     'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "#     'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "#     'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "#     'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "#     'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "#     'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "#         'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "#     'albert_en_base':\n",
    "#         'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "#     'electra_small':\n",
    "#         'https://tfhub.dev/google/electra_small/2',\n",
    "#     'electra_base':\n",
    "#         'https://tfhub.dev/google/electra_base/2',\n",
    "#     'experts_pubmed':\n",
    "#         'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "#     'experts_wiki_books':\n",
    "#         'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "#     'talking-heads_base':\n",
    "#         'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "# }\n",
    "\n",
    "# map_model_to_preprocess = {\n",
    "#     'bert_en_uncased_L-12_H-768_A-12':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'bert_en_cased_L-12_H-768_A-12':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'bert_multi_cased_L-12_H-768_A-12':\n",
    "#         'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "#     'albert_en_base':\n",
    "#         'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "#     'electra_small':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'electra_base':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'experts_pubmed':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'experts_wiki_books':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "#     'talking-heads_base':\n",
    "#         'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "# }\n",
    "\n",
    "# tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "# tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "# print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "# print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OM-23rpTxKiF"
   },
   "outputs": [],
   "source": [
    "# bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
    "# text_test = [\"this is an amazing movie\"]\n",
    "# text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "# print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "# print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "# print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "# print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "# print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHqmgSCPXHv9"
   },
   "source": [
    "#### BERT Model (Using Google's Tensorflow Tutorial)\n",
    "\n",
    "[Link](https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/classify_text_with_bert.ipynb#scrollTo=_OoF9mebuSZc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XzC5ycXzXLzY",
    "outputId": "6841f280-3a1c-4cc3-eaff-bbe41cd89074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `shutil` not found.\n"
     ]
    }
   ],
   "source": [
    "# A dependency of the preprocessing for BERT inputs\n",
    "!pip install -q -U \"tensorflow-text==2.8.*\"\n",
    "!pip install -q tf-models-official==2.7.0\n",
    "\n",
    "import os\n",
    "import shutil?\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pc9E55PfXo-7"
   },
   "outputs": [],
   "source": [
    "# Get BERT Model\n",
    "\n",
    "# bert_model_name = 'small_bert/bert_en_uncased_L-2_H-128_A-2'\n",
    "\n",
    "# \n",
    "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1'\n",
    "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "\n",
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XA_zasFLYo3G",
    "outputId": "9049d73c-51bd-4321-9c47-1f409f062d1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_word_ids', 'input_type_ids', 'input_mask']\n",
      "Shape      : (1, 128)\n",
      "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1\n",
      "Pooled Outputs Shape:(1, 128)\n",
      "Pooled Outputs Values:[-0.9999944   0.14341964 -0.9989779   0.9951448  -0.9997457   0.9131292\n",
      " -0.9961582  -0.9709751   0.09740015  0.0190705  -0.8488176  -0.09385537]\n",
      "Sequence Outputs Shape:(1, 128, 128)\n",
      "Sequence Outputs Values:[[-0.4372372  -1.0138292  -2.3744745  ... -0.7589708  -2.0910308\n",
      "  -0.25810054]\n",
      " [-1.3369715  -0.3688024   0.578688   ... -2.1810167  -1.7530919\n",
      "  -0.09555068]\n",
      " [-1.0607054  -0.30371025  0.34461316 ... -1.2898598  -1.9519895\n",
      "  -0.12230304]\n",
      " ...\n",
      " [-0.8602272  -0.5440616   0.6583734  ... -1.4765679  -1.7518611\n",
      "   1.1197371 ]\n",
      " [-0.46869004 -0.57152414  0.6725662  ... -1.7302345  -1.9740779\n",
      "   0.9747932 ]\n",
      " [ 0.0203665  -0.7551184   0.59482396 ... -1.9656779  -1.9051421\n",
      "   0.48970217]]\n"
     ]
    }
   ],
   "source": [
    "text_test = ['this is such an amazing movie!']\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "# text_preprocessed = bert_preprocess_model(data_train[\"sentence_cleaned\"])\n",
    "\n",
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')\n",
    "\n",
    "\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDtYhj0SaH7y",
    "tags": []
   },
   "source": [
    "### METHOD 1: Word Embedding\n",
    "\n",
    "I did pre-processing, word stemming, and stuff like that in Data Cleaning. The simplest way avoid words not being found in a database is if word stemming is not performed on the dataset (or as I just found out, use lemmization instead. More computationally complex but better for actually working with word embedding techniques (I think))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IyQ0gXpbrWuW"
   },
   "source": [
    "Partial reference: Find words in the Word2VecKeyedVector (using 2.3 in source https://github.com/adsieg/Multi_Text_Classification/blob/master/%5BIntroduction%5D%20-%20Big%20tutorial%20-%20Text%20Classification.ipynb) by using `Word2VecKeyedVector.index2word`. This returns a list of the word2vec array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7otfrHqvs_4S"
   },
   "source": [
    "Instructions used for pre-processing (this part): https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794 (as posted on Feb.17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rrmiLXAPbty"
   },
   "source": [
    "For CNN (not attempted): https://medium.com/saarthi-ai/sentence-classification-using-convolutional-neural-networks-ddad72c7048c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I4X05qMsQmcl",
    "outputId": "6fba3100-a00f-4acb-ebe9-8ce4d377524b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 104.8/104.8MB downloaded\n",
      "/root/gensim-data/glove-twitter-25/glove-twitter-25.gz\n"
     ]
    }
   ],
   "source": [
    "# DO NOT RUN THIS BLOCK MORE THAN ONCE IN ONE SESSION\n",
    "# Import gensim data\n",
    "import gensim.downloader as api\n",
    "import gensim\n",
    "# Load a pre-trained word embedding model\n",
    "# Gensim data obtained from https://github.com/RaRe-Technologies/gensim-data (official source)\n",
    "word_embed = api.load('glove-twitter-25')\n",
    "# word_embed = api.load('word2vec-google-news-300') # This is 1.6GB... good luck doing this on Google Colab...\n",
    "# model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "print(api.load(\"glove-twitter-25\", return_path=True))\n",
    "# print(api.load('word2vec-google-news-300', return_path=True))\n",
    "\n",
    "# Check dimension of word vectors\n",
    "# model.vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkZ0LrphPbtz"
   },
   "source": [
    "#### Pre-Processing\n",
    "Using Keras for Preprocessing. Steps taken:\n",
    "1. Called the Tokenizer object\n",
    "2. Added Training Set Vocabulary to the Tokenizer object (`fit_on_texts`)\n",
    "    * Viewed the added vocabulary using `tokenizer.word_index` command.\n",
    "3. Convert all text to numeric values using `text_to_sequences` method function\n",
    "4. Padded the length of every sample so that the input matrix would be equal in size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "GZJVqjx0gILU",
    "outputId": "2b5e3197-d430-483f-b937-7ef5e95c457d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-1e3475c6-1624-4ecd-84e0-3786bbfc8b31\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_enc</th>\n",
       "      <th>sentence_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "      <td>didnt feel humiliated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "      <td>go feeling hopeless damned hopeful around some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>im grabbing minute post feel greedy wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "      <td>3</td>\n",
       "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>feeling grouchy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e3475c6-1624-4ecd-84e0-3786bbfc8b31')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-1e3475c6-1624-4ecd-84e0-3786bbfc8b31 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-1e3475c6-1624-4ecd-84e0-3786bbfc8b31');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                            sentence  emotion  emotion_enc  \\\n",
       "0                            i didnt feel humiliated  sadness            4   \n",
       "1  i can go from feeling so hopeless to so damned...  sadness            4   \n",
       "2   im grabbing a minute to post i feel greedy wrong    anger            0   \n",
       "3  i am ever feeling nostalgic about the fireplac...     love            3   \n",
       "4                               i am feeling grouchy    anger            0   \n",
       "\n",
       "                                    sentence_cleaned  \n",
       "0                              didnt feel humiliated  \n",
       "1  go feeling hopeless damned hopeful around some...  \n",
       "2          im grabbing minute post feel greedy wrong  \n",
       "3  ever feeling nostalgic fireplace know still pr...  \n",
       "4                                    feeling grouchy  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EUzjRawYPbtz"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import seaborn as sns\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data_train[\"sentence_cleaned\"])\n",
    "dic_vocabulary = tokenizer.word_index\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(data_train[\"sentence_cleaned\"])\n",
    "X_test = tokenizer.texts_to_sequences(data_test[\"sentence_cleaned\"])\n",
    "X_val = tokenizer.texts_to_sequences(data_val[\"sentence_cleaned\"])\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffDRXRISyhsg"
   },
   "source": [
    "Finding out which data set has the longest \"sentence\" a.k.a. useful words that we did not eliminate via lemmization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TfsSVjnqwRRM",
    "outputId": "1ff3a568-c798-412d-c6b2-4625b079f76b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train, Longest ID: 35, Average ID length: 9.3530625\n",
      "X_test, Longest ID: 30, Average ID length: 8.85\n",
      "X_val, Longest ID: 28, Average ID length: 8.764\n"
     ]
    }
   ],
   "source": [
    "# string_name = ['X_train', 'X_test', 'X_val']\n",
    "dict_data = {'X_train': X_train,\n",
    "             'X_test': X_test,\n",
    "             'X_val': X_val}\n",
    "histo_plot_data = np.zeros((3,35))\n",
    "\n",
    "tmp_counter = 0;\n",
    "for key, value in dict_data.items():\n",
    "    feedback = 0;\n",
    "    feedback_sum = 0;\n",
    "    for i in value:\n",
    "        histo_plot_data[tmp_counter, len(i)-1] += 1\n",
    "        feedback_sum += len(i)\n",
    "        if len(i) > feedback:\n",
    "            feedback = len(i)\n",
    "    print(f\"{key}, Longest ID: {feedback}, Average ID length: {feedback_sum/len(value)}\")\n",
    "    tmp_counter += 1\n",
    "del tmp_counter\n",
    "\n",
    "# Longest sentence has 35 elements. Average is around 10.\n",
    "# TODO: This value, which influences padding, should be adjusted I think...\n",
    "maxlen = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "uJKPzj9zObv0",
    "outputId": "2d9a792a-6304-44dc-8cec-fdaf373b998c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 35 artists>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the ID histogram to see the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.barh(range(1,35+1), histo_plot_data[0,:])\n",
    "plt.barh(range(1,35+1), histo_plot_data[1,:])\n",
    "plt.barh(range(1,35+1), histo_plot_data[2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3pBemRHwEN9"
   },
   "source": [
    "Pad each sample to the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "WhQBTFT6v54X",
    "outputId": "befd3a4e-dd54-454d-c462-f728890b1890"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "X_val = pad_sequences(X_val, padding='post', maxlen=maxlen)\n",
    "\n",
    "# Honestly don't know what this is doing, I just followed the website's instructions\n",
    "# Looks like this shows the padding heat map or something similar to that\n",
    "sns.heatmap(X_train==0, vmin=0, vmax=1, cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sh1SpY8hvmmN"
   },
   "source": [
    "Obtain the Embedding Matrix, which is necessary for the machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SjN7DmxxUp3b",
    "outputId": "6af947d2-48e9-415d-e3e9-ebe5f31ced57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in dictionary that have been assigned a matrix of 0's: 872\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.zeros((len(dic_vocabulary)+1, 25))\n",
    "counter=0\n",
    "for word, idx in dic_vocabulary.items():\n",
    "    # embeddings[idx] = word_embed[word]\n",
    "    try:\n",
    "        # Reminder: word_embed is the pre-trained word embedding model...\n",
    "        embeddings[idx] = word_embed[word]\n",
    "    except:\n",
    "        counter += 1\n",
    "        pass\n",
    "\n",
    "print(f\"Number of words in dictionary that have been assigned a matrix of 0's: {counter}\")\n",
    "\n",
    "# word = \"data\"\n",
    "# print(\"dic[word]:\", dic_vocabulary[word], \"|idx\")\n",
    "# print(\"embeddings[idx]:\", embeddings[dic_vocabulary[word]].shape, \n",
    "#       \"|vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_0cPtAOdcek"
   },
   "source": [
    "#### Neural Network\n",
    "\n",
    "Referencing source: https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Be-tKnSqdjLK",
    "outputId": "1f4e33f4-d45a-41a0-ee0d-c77a1b8f4dfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 20, 25)       336975      ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " permute_4 (Permute)            (None, 25, 20)       0           ['embedding_4[0][0]']            \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 25, 20)       420         ['permute_4[0][0]']              \n",
      "                                                                                                  \n",
      " attention (Permute)            (None, 20, 25)       0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 20, 25)       0           ['embedding_4[0][0]',            \n",
      "                                                                  'attention[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional_8 (Bidirectional  (None, 20, 40)      7360        ['multiply_4[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_9 (Bidirectional  (None, 40)          9760        ['bidirectional_8[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 64)           2624        ['bidirectional_9[0][0]']        \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 6)            390         ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 357,529\n",
      "Trainable params: 357,529\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers, models, optimizers\n",
    "import keras\n",
    "\n",
    "def attention_layer(inputs, neurons):\n",
    "    x = layers.Permute((2,1))(inputs)\n",
    "    x = layers.Dense(neurons, activation=\"softmax\")(x)\n",
    "    x = layers.Permute((2,1), name='attention')(x)\n",
    "    x = layers.multiply([inputs, x])\n",
    "    return x\n",
    "\n",
    "# input\n",
    "x_in = layers.Input(shape=(maxlen,))\n",
    "\n",
    "# embedding\n",
    "# trainable=False means that these embedding weights will not change. What if they did though?\n",
    "x = layers.Embedding(input_dim=embeddings.shape[0],\n",
    "                     output_dim=embeddings.shape[1],\n",
    "                     weights=[embeddings],\n",
    "                     input_length=maxlen, trainable=True)(x_in)\n",
    "\n",
    "# apply attention\n",
    "x = attention_layer(x, neurons=maxlen)\n",
    "\n",
    "# 2 layers of bidirectional lstm\n",
    "x = layers.Bidirectional(layers.LSTM(units=maxlen, dropout=0.2, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(units=maxlen, dropout=0.2))(x)\n",
    "\n",
    "# final dense layers\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "y_out = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "model = models.Model(x_in, y_out)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SGE2_s1_gB7B",
    "outputId": "46976649-cccd-4d09-c6f7-d1df10388115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "500/500 [==============================] - 21s 29ms/step - loss: 1.4924 - accuracy: 0.4114 - val_loss: 1.3052 - val_accuracy: 0.5155\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 1.2320 - accuracy: 0.5321 - val_loss: 1.1119 - val_accuracy: 0.5715\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 1.0116 - accuracy: 0.6001 - val_loss: 0.8995 - val_accuracy: 0.6400\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.7826 - accuracy: 0.6952 - val_loss: 0.7254 - val_accuracy: 0.7350\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6021 - accuracy: 0.7732 - val_loss: 0.5989 - val_accuracy: 0.7830\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 14s 29ms/step - loss: 0.4814 - accuracy: 0.8194 - val_loss: 0.4981 - val_accuracy: 0.8325\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.3927 - accuracy: 0.8574 - val_loss: 0.4569 - val_accuracy: 0.8455\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.3319 - accuracy: 0.8813 - val_loss: 0.4304 - val_accuracy: 0.8555\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.2837 - accuracy: 0.8967 - val_loss: 0.4373 - val_accuracy: 0.8585\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.2493 - accuracy: 0.9097 - val_loss: 0.4196 - val_accuracy: 0.8560\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.2239 - accuracy: 0.9184 - val_loss: 0.4091 - val_accuracy: 0.8650\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.1875 - accuracy: 0.9306 - val_loss: 0.4483 - val_accuracy: 0.8685\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.1829 - accuracy: 0.9332 - val_loss: 0.3957 - val_accuracy: 0.8755\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.1668 - accuracy: 0.9396 - val_loss: 0.3557 - val_accuracy: 0.8825\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.1514 - accuracy: 0.9438 - val_loss: 0.3677 - val_accuracy: 0.8805\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.1351 - accuracy: 0.9503 - val_loss: 0.3921 - val_accuracy: 0.8805\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.1250 - accuracy: 0.9538 - val_loss: 0.3749 - val_accuracy: 0.8830\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - 14s 28ms/step - loss: 0.1150 - accuracy: 0.9576 - val_loss: 0.3877 - val_accuracy: 0.8875\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - 21s 41ms/step - loss: 0.1091 - accuracy: 0.9592 - val_loss: 0.4092 - val_accuracy: 0.8825\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - 14s 29ms/step - loss: 0.1024 - accuracy: 0.9624 - val_loss: 0.4094 - val_accuracy: 0.8835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff5cdce0dd0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The fitting method should be placed in a variable so that results can be easily extracted later...\n",
    "# For now, I would like to see training happening in real time, so making it verbose I guess.\n",
    "# Still need to adjust hyper-parameters for better results... if I can get better results.\n",
    "# batch_size=256 (default given on the website)\n",
    "model.fit(x=X_train, y=data_train['emotion_enc'], batch_size=32, epochs=20,\n",
    "                     shuffle=True, verbose=1, validation_data=[X_val, data_val['emotion_enc']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhTx_KSoc9Yn"
   },
   "source": [
    "Test data on the fitted model using `model.evaluate()`. Also get the probabilities of each sentence via `model.predict()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DsF5kG-Tc6Mc",
    "outputId": "a7e7c135-9db5-4fd4-decc-cfb64ce83f2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 13s 5ms/step - loss: 0.4022 - accuracy: 0.8830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.2568888e-05, 2.1097869e-05, 4.4417099e-04, 5.7640176e-07,\n",
       "        9.9948114e-01, 4.1913924e-07],\n",
       "       [8.9937239e-05, 5.2907642e-05, 2.0784813e-05, 1.3567708e-07,\n",
       "        9.9983609e-01, 1.5043787e-07],\n",
       "       [1.1101728e-05, 9.8037917e-06, 2.3443909e-05, 6.2540195e-08,\n",
       "        9.9995542e-01, 6.2094820e-08],\n",
       "       ...,\n",
       "       [4.5340485e-08, 1.3153849e-08, 9.9998450e-01, 1.3308581e-05,\n",
       "        2.1206949e-06, 1.0057495e-08],\n",
       "       [7.6205065e-06, 4.2420129e-06, 9.9926525e-01, 6.4096239e-04,\n",
       "        7.4186173e-05, 7.6518290e-06],\n",
       "       [4.0333030e-06, 4.6915185e-02, 8.8759256e-04, 6.3963824e-05,\n",
       "        1.4737179e-05, 9.5211440e-01]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, data_test[\"emotion_enc\"], batch_size=1)\n",
    "model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ifCzi282UO64",
    "UFTJfJkrO06u",
    "LWVt__H7R9zl",
    "PLR3Zasdel1c",
    "0DW_8szfEo1T",
    "nMPQ0676j_BB",
    "fjW1a7SQwK57",
    "WDtYhj0SaH7y",
    "zkZ0LrphPbtz"
   ],
   "history_visible": true,
   "name": "EECE_571T_Project_BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "eece571T",
   "language": "python",
   "name": "eece571t"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
